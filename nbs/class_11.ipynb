{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary evaluation\n",
    "\n",
    "Today we'll take a look at how we can evaluate the quality of model-generated summaries in different ways.\n",
    "\n",
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "%%python -m spacy download en_core_web_sm\n",
    "%%pip install rouge_score bert_score blanc nltk sentencepiece protobuf transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "We'll use a small slice of the English part of the `xlsum` dataset from the `datasets` library. You can take a look at what kind of data this includes [here](https://huggingface.co/datasets/csebuetnlp/xlsum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"csebuetnlp/xlsum\", \"english\", split='train[:1%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'summary', 'text'],\n",
       "    num_rows: 3065\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The articles are in the `text` column and the summaries are in the `summary` column. Let's extract them and take a look at a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Met Office has issued a yellow weather warning for wind covering Wales and England, starting from 21:00 GMT on Wednesday evening. Travel and power are both likely to be disrupted, with the warning to remain in place until 15:00 on Thursday. Gusts of 55mph (88kmh) are likely and could hit up to 70mph on coasts and hills, with heavy and blustery showers.',\n",
       " 'Atlantis Resources unveiled the marine energy device at Invergordon ahead of it being shipped to Kirkwall. Trials on the device will now be run at the European Marine Energy Centre test site off Eday. The device stands 22.5m (73ft) tall, weighs 1,300 tonnes and has two sets of blades on a single unit. It could generate enough power for 1,000 homes.',\n",
       " 'Police were called to the scene outside the Coral shop on Compton Road in Harehills just before 14:00 BST. The man was taken to hospital for treatment but his condition is not known. West Yorkshire Police said the area has been cordoned off and officers remain at the scene. The force has appealed for information.',\n",
       " 'Anthony ZurcherNorth America reporter@awzurcheron Twitter With tensions rising between the US and Iran, the long-term consequences will largely depend on the nature of Iran\\'s response to the attack and the intensity of any conflict that follows. If the end result is a US withdrawal from Iraq, the politics of the situation could be turned on its head, with hawks doing the howling and non-interventionists celebrating. In the short term, however, there are already some possible implications both for the Democratic presidential primaries that begin in less than a month and November\\'s general election contest. A wartime president? Traditionally, a US president facing a major foreign policy crisis benefits from at least a short-term bump in public support. The \"rally around the flag\" effect boosted George HW Bush\\'s standing during the 1991 Gulf War. George W Bush saw his approval surge to record levels in the days after the September 11 attacks and subsequent bombing of Afghanistan. Those were massive military engagements, however. When the stakes have been lower, the tangible political benefits - at least in terms of polling - are harder to discern. Barack Obama saw no change in his approval ratings during the 2011 air war in Libya. When Donald Trump fired missiles at a Syrian air base in response to that nation\\'s use of chemical weapons, the slight increase in his ratings appear in hindsight to be little more than statistical noise for a man whose approval has been relatively stable throughout his presidency. The first survey following the Soleimani strike suggests the public will be as sharply divided on Trump\\'s handling of the situation as it has been on everything else this president has done. A slim plurality approve of the action, but a similar plurality also express concern that the president did not \"plan carefully enough\". Short of a stunning military victory or a protracted bloody fight, the end result could be simply more of the same when it comes to views on the Trump presidency. Republican support Trump could end up benefiting from this episode, however, the way he always seems to benefit from his controversial or incendiary moves - by rallying his base. In that same Huffington Post poll, 83% of Republicans said they approved of the airstrike. Meanwhile, the president\\'s supporters have gone on the attack, treating the Soleimani strike as the latest way to \"trigger\" political opponents. On social media, a common Trumpian response for those expressing concerns about the consequences of the Soleimani strike is \"sorry for your loss\". The Babylon Bee, a conservative parody website, joked that Democrats want to fly US flags at half-mast to mourn Soleimani\\'s death. The drama in the Middle East may also help the president by turning national attention away from his impeachment and looming Senate trial. That seemed to be on the president\\'s mind in multiple tweets Monday morning. \"To be spending time on this political Hoax at this moment in our history, when I am so busy, is sad!\" he wrote. Democratic doves On the Democratic side, the Soleimani strike could invigorate an anti-war movement within the party that has not seriously flexed its muscles since the height of the Iraq War. Bernie Sanders, one of the Democratic front-runners, was quick to stake out his peace candidate credentials. \"I was right about Vietnam. I was right about Iraq. I will do everything in my power to prevent a war with Iran,\" he wrote in a tweet that included a video about his anti-war efforts. \"I apologize to no one.\" Tulsi Gabbard, another candidate who has vigorously opposed what she views as \"regime-change wars\" pursued by both parties, said the Soleimani strike was an \"act of war\" that violated the US constitution. Those statements stood in contrast to other Democratic candidates, who both condemned Soleimani\\'s record of support for proxy wars against US forces in the region and criticised the wisdom of the attack. \"There are serious questions about how this decision was made and whether we are prepared for the consequences,\" said Pete Buttigieg. Elizabeth Warren called Soleimani a \"murderer\". Amy Klobuchar expressed concerns for US troop safety in the region. Meanwhile, former New York Mayor Michael Bloomberg took aim at Sanders, saying it was \"outrageous\" for the Vermont senator to call the strike an \"assassination\" (a word used by several Democratic candidates). \"This is a guy who had an awful amount of American blood on his hands,\" Bloomberg said. \"Nobody that I know of would think that we did something wrong in getting the general.\" A rift within the party between progressives and moderates was on display time and again when the topic turned to healthcare during the debates. If the Iran crisis gets hot, the use of military force could become an equally divisive topic. More on the 2020 race Biden\\'s challenge The Huffpost poll on the Soleimani strike had some particularly good news for front-runner Joe Biden, with 62% of Democratic and Democratic-leaning voters saying they \"trust\" him on Iran. That\\'s well ahead of Sanders and Warren, who 47% said they trust on the subject. Such a response isn\\'t surprising, given Biden\\'s long record of foreign policy experience, including eight years as vice-president and a lengthy tenure as chair of the Senate foreign relations committee. That track record isn\\'t entirely a blessing, however, as a focus on the Middle East has once again turned attention to Biden\\'s support for the 2003 Iraq War - and his sometimes muddled defence of it. In response to a question from a voter in Iowa on Saturday, Biden said that while he voted for the Iraq War authorisation, he opposed President Bush\\'s handling of the conflict \"from the very moment\" it began. Biden had spoken in support of the war before and after it was launched, however, and only first expressed regrets about his vote starting in 2005. The more Biden twists and turns to qualify his Iraq War support, the more media outlets will point out where he is misleading or exaggerating, giving the story national attention - and the more Biden\\'s opponents could sense a weakness they could exploit. No more oxygen As if December\\'s impeachment fight didn\\'t make it hard enough for back-of-the-pack Democrats to generate attention amid a flood of major breaking news, now Iran is set to compete with a Senate trial of the president for top billing. That\\'s bad news for candidates like Cory Booker, Deval Patrick, Tom Steyer and the few other stragglers who are still in the race but languishing in the polls and below the cut-off mark to qualify for upcoming primary debates. It could also spell trouble for Klobuchar, whose surge in fundraising and Iowa polling of late could prove short-lived if voters become preoccupied with events overseas. In presidential campaign politics, it helps to be the candidate who gets hot late in the game. With the Iran crisis looming, however, it may end up already being too late. Who will take on Trump in 2020?',\n",
       " 'By Debbie JacksonBBC Scotland But while most of us are giving up trips out of the house, many health workers across the country are making an even bigger sacrifice. Those who are on the front line, experiencing face-to-face contact with patients who have the virus, are putting themselves at risk every day. Some of them have made the difficult decision to stay away from their families to avoid passing on that risk. Ambulance technician Jamie Kennedy from Glasgow is one of them. Jamie, 38, moved out of his family home 11 days ago and into a hotel so that he can carry on doing his job without worrying about bringing the virus home to his wife and two children. He can also continue to do vital work if any of his family have to self-isolate. He told the BBC: \"I am staying in a hotel which offered free rooms to NHS staff at the start of lockdown. The hotel is almost full of NHS staff. \"It was a difficult decision but when I saw the situation getting worse and worse I had the discussion with my wife Ashley. \"It was a purely personal decision, but I would never forgive myself if anything happened and if the kids got ill. I am out in the community all day and if I went in and caused them to get sick, I would never forgive myself.\" Tuesday\\'s figures saw the number of patients testing positive for Covid-19 in Scotland rise to 6,358. A total of 615 people have died, including two health and care workers. \\'Symptoms present in the majority\\' Jamie\\'s shifts for the Scottish Ambulance Service are completely consumed by coronavirus right now. \"In the majority of calls one or more symptoms are present and we have to treat it as a potential case,\" he said. \" It could be up to nine patients in a shift. \"Thankfully the morale is high and we are well looked after. My manager calls to check we are doing okay.\" Contact with his wife and children is limited to video calls and one socially distant trip a week to drop off groceries. Having to see them from a distance is heartbreaking. He said: \"I do a big shop for them and take it over to the back garden and talk to them from the back of the garden. \"It\\'s hard. I was there the other day and my daughter, who is eight, wanted a hug and she was crying. That was difficult. \"There is no end in sight right now but I\\'ll stay away from my wife and kids as long as I need to, to keep them safe.\" Jamie\\'s wife Ashley says like many families of front-line workers, they are worried. \\'The right thing\\' She said: \"The children have taken it pretty bad but understand how important their daddy\\'s job is. \"It\\'s been hard for me to see the children so upset and Jamie upset leaving, but I\\'ve had to stay strong for him to be able to put his all into his job and strong for the kids to feel secure and safe.\" \"It\\'s hard not seeing him and having a wee cuddle but we know it\\'s the right and safest thing to do. \"Jamie is the most selfless man I\\'ve ever known. \"We as a family who is affected by this virus cannot stress enough that everyone keeps to the stay at home guidelines. The more everyone stays home the sooner the virus will die off and the sooner we can get Jamie home.\" \\'We just wanted to do our bit to help\\' Scottish hotel group Manorview is one of many hotel companies across the country keeping their doors open to NHS staff at this uncertain time. The company made the decision to stop trading on 18 March. Five days later its hotels opened up again to front-line health staff, for no cost. They\\'ve had more than 2,000 room bookings, with three venues fully booked until the start of May. Managing director David Tracey said the group was humbled to hear some of the stories of NHS workers who are trying to keep working to look after patients, while also trying to protect their own families at home. He said: \"More than ever, we need to secure the health, safety and wellbeing of our NHS team. They are on the front line, helping us all, and saving lives. We are very thankful for the work they do. We are there for them and we\\'re proud to be of service, and in a position to help. \"The attitude of our team has made this negative situation more positive.\"',\n",
       " 'He was arrested on Saturday morning and is currently in custody. Detectives from the Causeway Coast and Glens Criminal Investigations Branch also searched an address in Ballymoney and a number of items were seized. Police have appealed for those with information about criminality linked to paramilitaries to contact them.',\n",
       " 'Coventry firm Travel de Courcey is to introduce the three buses in May next year, on its Park and Ride South route. The 38-seat buses will run between the Memorial Park in Kenilworth Road and the city centre using power points already installed by the council. A Travel de Courcey spokesman said the company had been looking to improve its vehicles, both environmentally and from a passenger perspective. The buses, Versa EV\\'s, are provided by Optare plc of Leeds. Travel de Courcey has invested £400,000, the government\\'s Green Bus Fund has invested £300,000 and Centro, which looks after public transport in the West Midlands, has contributed £100,000. Mike de Courcey, from the bus firm, said when it heard about the Green Bus Fund it seemed a good opportunity for the firm. \"The electric buses are ideal for urban driving where the vehicle is stopping and starting,\" he said.',\n",
       " 'St Helier Deputy, Trevor Pitman, has put forward changes to proposals by a States group to cut back the number of senators from 12 to eight. He wants the States to go further, with numbers cut to six, saying it would save more money. Plans to reform the structure of the States are under review and could be the subject of a referendum.',\n",
       " 'Managers at Alliance Boots said a fall in demand for products made for other companies meant it had to reduce capacity. Bosses said the posts will go over the next two years and added they would make efforts to redeploy staff. The division of Boots involved, BCM, currently employs 1,200 people and will now focus on own brand beauty and skincare products. Stephen Le Hane, an HR director for the company, said: \"You will appreciate that many of our customers are suffering from the recession as most companies are in the UK. \"The amount of demand they have for the products in BCM has gone down and as there are quite high fixed costs in manufacturing, those adjustments in their volume requirements for us can have an impact on the profitability and success of the BCM business.\"',\n",
       " 'The course will look at intelligence history and Bletchley Park focusing on the World War II code breakers. Course director, Professor Anthony Glees said it was an opportunity to work with Bletchley\\'s previously unresearched archives. The Master of Arts degree explores how military intelligence developed. The degree is the university\\'s newest course run by the Centre for Security and Intelligence Studies. Professor Glees said: \"The course will reveal fresh insights into how the war was fought, which will be totally unique for students at this level.\"']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = ds[\"text\"][0:10]\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Winds could reach gale force in Wales with stormy weather set to hit the whole of the country this week.',\n",
       " 'The massive tidal turbine AK1000 has been installed in 35m (114.8ft) of water at a test site in Orkney.',\n",
       " 'A man has been stabbed in broad daylight outside a betting shop in Leeds.',\n",
       " 'It was inevitable that the fallout from the US airstrike that killed Iranian General Qasem Soleimani would spill into presidential politics. Everything spills into presidential politics these days, and this is without a doubt a major story.',\n",
       " 'Week four of social distancing is starting to take its toll.',\n",
       " 'A 37-year-old man has been arrested as part an ongoing investigation into criminality linked to the North Antrim Ulster Defence Association (UDA).',\n",
       " 'Electric buses will soon be running on the roads in Coventry.',\n",
       " 'A Jersey deputy is calling on the number of States members to be reduced more than current proposals.',\n",
       " 'About 200 posts are to go at the Boots site in Nottingham.',\n",
       " 'A degree in military intelligence studies, highlighting the importance of Bletchley Park is to be offered by The University of Buckingham.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_summaries = ds[\"summary\"][0:10]\n",
    "reference_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss:\n",
    "- Based on these examples, what do you think of the quality of the dataset?\n",
    "- Do you foresee any potential pitfalls for evaluation, based on your observations?\n",
    "\n",
    "Let's take a look into the density of the summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "from utils.fragments import Fragments\n",
    "\n",
    "fragment = [Fragments(summary, article, lang=\"en\") for summary, article in zip(reference_summaries, articles)]\n",
    "density = [frag.density() for frag in fragment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(filter(lambda x: x <= 1.5, density))) / len(density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remember, summaries with density values below 1.5 are considered abstractive, meaning these seem to be highly abstractive summaries.\n",
    "However, the density values are not a perfect measure of abstractive quality:\n",
    "- Can you think of a way we might be able to \"game\" the density metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating summaries\n",
    "Now let's generate some summaries using a pre-trained model. We'll use the `mt5-small` model from the `transformers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"google/mt5-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, min_length=10, max_length=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make everything a bit easier for ourselves, let's make a function which:\n",
    "1. Takes an input text\n",
    "2. Tokenises the text (remember to set the padding and truncation arguments to True)\n",
    "3. Generates a summary based on the tokenised input (and prompt, if you're so inclined)\n",
    "4. Decodes the generated summary from tokens into words, and\n",
    "5. Returns the output\n",
    "\n",
    "(Hint: there is one potential solution in the class_8_solution notebook, if you're in need :-))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEL \n",
    "def your_pipeline_function(input_text):\n",
    "    output = model.generate(tokenizer(input_text, return_tensors=\"pt\")[\"input_ids\"])\n",
    "    return tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use that function to generate some summaries for the articles in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/generation/utils.py:1375: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<pad> <extra_id_0>.com.au./ <extra_id_10>.</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_pipeline_function(articles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_summaries = [your_pipeline_function(article) for article in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad> <extra_id_0>.com.au./ <extra_id_10>.</s>',\n",
       " '<pad> <extra_id_0>.com <extra_id_10>.com an <extra_id_11>.</s>',\n",
       " '<pad> <extra_id_0>.com.uk.com <extra_id_10>.com</s>',\n",
       " '<pad> <extra_id_0> the debate. Politics.com</s>',\n",
       " '<pad> <extra_id_0> Jamie Kennedy says: \"It was hard.</s>',\n",
       " '<pad> <extra_id_0>. ) <extra_id_37>.graves. <extra_id_4> - Criminal Investigations</s>',\n",
       " '<pad> <extra_id_0> - Coventry - Coventry</s>',\n",
       " '<pad> <extra_id_0> - St Helier - St Helier</s>',\n",
       " '<pad> <extra_id_0> - Consumer Reports - Business</s>',\n",
       " '<pad> <extra_id_0>.com.uk.com/courses.</s>']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Now let's evaluate the quality of the generated summaries with some commonly used metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.025069921179760996,\n",
       " 'rouge2': 0.0,\n",
       " 'rougeL': 0.02265446224256293,\n",
       " 'rougeLsum': 0.025069921179760996}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "rouge = load(\"rouge\")\n",
    "rouge.compute(references=reference_summaries, predictions=generated_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at the ROUGE scores for the individual summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.08695652173913043,\n",
       "  0.0,\n",
       "  0.052631578947368425,\n",
       "  0.1111111111111111,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'rouge2': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " 'rougeL': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.08695652173913043,\n",
       "  0.0,\n",
       "  0.052631578947368425,\n",
       "  0.1111111111111111,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'rougeLsum': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.08695652173913043,\n",
       "  0.0,\n",
       "  0.052631578947368425,\n",
       "  0.1111111111111111,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.compute(references=reference_summaries, predictions=generated_summaries, use_aggregator=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BERTScore metric does not use an aggregator, but we can average the scores ourselves to get an overall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': [0.7897378206253052,\n",
       "  0.765849232673645,\n",
       "  0.7976936101913452,\n",
       "  0.7899143695831299,\n",
       "  0.8089548945426941,\n",
       "  0.7626368999481201,\n",
       "  0.8046826124191284,\n",
       "  0.7890909314155579,\n",
       "  0.7653211951255798,\n",
       "  0.8175321221351624],\n",
       " 'recall': [0.8295824527740479,\n",
       "  0.7967321872711182,\n",
       "  0.8265303373336792,\n",
       "  0.8113272190093994,\n",
       "  0.852196991443634,\n",
       "  0.8178002834320068,\n",
       "  0.873009204864502,\n",
       "  0.8301175832748413,\n",
       "  0.8252493143081665,\n",
       "  0.8258839845657349],\n",
       " 'f1': [0.8091698884963989,\n",
       "  0.7809855341911316,\n",
       "  0.8118559718132019,\n",
       "  0.8004776239395142,\n",
       "  0.83001309633255,\n",
       "  0.7892558574676514,\n",
       "  0.8374545574188232,\n",
       "  0.8090844750404358,\n",
       "  0.7941563129425049,\n",
       "  0.8216868042945862],\n",
       " 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.44.2)'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "bertscores = bertscore.compute(references=reference_summaries, predictions=generated_summaries, lang=\"en\")\n",
    "bertscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7891413688659668, 0.8288429558277131, 0.8084140121936798)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean(bertscores[\"precision\"]), np.mean(bertscores[\"recall\"]), np.mean(bertscores[\"f1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try a reference-free metric, such as BLANC, in case we do not have access to reference summaries, or we do not want to rely on them due to quality, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 498/498 [00:23<00:00, 21.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.05405405405405406,\n",
       " 0.05555555555555555,\n",
       " 0.0,\n",
       " 0.014005602240896359,\n",
       " 0.014492753623188406,\n",
       " 0.06060606060606061,\n",
       " 0.044444444444444446,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.07407407407407407]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import blanc\n",
    "\n",
    "blanc = blanc.BlancHelp()\n",
    "blanc.eval_pairs(articles, generated_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss:\n",
    "- What do these values tell us about the quality of the generated summaries?\n",
    "- What are the strenghts and weaknesses of using reference-free metrics?\n",
    "- What are the potential weaknesses of using a less known metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Now, the summaries we generated aren't exactly great, likely because the mt5 model was not fine-tuned for that purpose.\n",
    "- Try to generate 10 new summaries using a model that has been fine-tuned for summarisation (e.g., our old friend, flan-t5-small)\n",
    "- When you have the summaries, evaluate them using the same quantitative metrics as before\n",
    "- Then try to conduct a qualitative evaluation of the summaries - in your groups, decide on some evalaution criteria (e.g., ranking, \"stars\", etc.), evaluate the summaries based on these criteria, and compare your results within the group and with the quantitative metrics\n",
    "\n",
    "### Bonus exercise\n",
    "Try to create a LLM judge that can evaluate the quality of the summaries based on the criteria you defined.\n",
    "- Load in a generative pre-trained model from huggingface\n",
    "- Prompt it with your evaluation criteria\n",
    "- Compare its evaluation with your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/au594328/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
